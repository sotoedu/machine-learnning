Colab에서 딥러닝 실행하기
https://colab.research.google.com/

CNN 모델을 이용한 고양이와 강아지 분류

Step1. 프로젝트 경로 생성

!rm -rf workspace/
!mkdir workspace/
!ls


Step2. 이미지 다운로드 및 압축 풀기

!wget --no-check-certificate https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip -O workspace/imageset.zip


Step3.압축 파일 풀기

import os
import zipfile

!ls workspace
baseDir = 'workspace/cats_and_dogs_filtered'
localZip = 'workspace/imageset.zip'

zipRef = zipfile.ZipFile(localZip, 'r')
zipRef.extractall('workspace/')
zipRef.close()

trainDir = os.path.join(baseDir, 'train')
validDir = os.path.join(baseDir, 'validation')

# 훈련용 고양이/개 이미지 경로지정
trainCatDir = os.path.join(trainDir, 'cats')
trainDogDir = os.path.join(trainDir, 'dogs')

# 테스트용 고양이/개 이미지 경로지정
validCatDir = os.path.join(validDir, 'cats')
validDogDir = os.path.join(validDir, 'dogs')

print('훈련용 고양이 이미지 수: ', len(os.listdir(trainCatDir)))
print('훈련용 강아지 이미지 수: ', len(os.listdir(trainDogDir)))
print('검증용 고양이 이미지 수: ', len(os.listdir(validCatDir)))
print('검증용 강아지 이미지 수: ', len(os.listdir(validDogDir)))


Step4. 훈련 고양이 이미지 확인

import matplotlib.pyplot as plt
from matplotlib.image import imread

# 훈련용 고양이 이미지 파일이름 
trainCatFileNames = os.listdir( trainCatDir )

fig = plt.gcf()
fig.set_size_inches(4*3, 4*3)

i = 0
for filename in trainCatFileNames[:16]:
  sp = plt.subplot(4, 4, i + 1)
  sp.axis('Off')
  image = imread(trainCatDir +'/'+ filename)
  plt.imshow(image)
  i = i + 1

# 이미지 확인
plt.show()


Step5. 훈련 강아지 이미지 확인

fig = plt.gcf()
fig.set_size_inches(4*3, 4*3)

# 훈련용 강아지 이미지 파일이름 
trainDogFileNames = os.listdir( trainDogDir )

i = 0
for filename in trainDogFileNames[:16]:
  sp = plt.subplot(4, 4, i + 1)
  sp.axis('Off')
  image = imread(trainDogDir +'/'+ filename)
  plt.imshow(image)
  i = i + 1

# 이미지 확인
plt.show()


Step6. 모델 생성하기

# 모델 생성
import sys
import matplotlib.pyplot as plt

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import RMSprop


# CNN 모델 정의
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(150, 150, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(1, activation='sigmoid'))

# 모델 컴파일
# 1) SGD
#opt = SGD(learning_rate=0.001, momentum=0.9)
#model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])

# 2) RMS
model.compile(optimizer=RMSprop(learning_rate=0.001),loss='binary_crossentropy', metrics = ['accuracy'])



Step7. 모델 학습

epochs=10
batchSize=10

# create data generator
datagen = ImageDataGenerator(rescale=1.0/255.0)

# prepare iterators
trainDo = datagen.flow_from_directory(trainDir, class_mode='binary', batch_size=batchSize, target_size=(150, 150))
testDo = datagen.flow_from_directory(validDir, class_mode='binary', batch_size=batchSize, target_size=(150, 150))

# fit model
history = model.fit(trainDo, steps_per_epoch=epochs, epochs=epochs, validation_data=testDo, validation_steps=epochs,  verbose=1)

Setp8. 성능평가

loss = history.history['loss']
valLoss = history.history['val_loss']
accuracy = history.history['accuracy']
valAccuracy = history.history['val_accuracy']

_, acc = model.evaluate(testDo, steps=epochs, verbose=2)
print('> %.3f' % (acc * 100.0))

plt.figure(figsize=(8,8))
plt.subplot(1, 2, 1)
plt.plot(range(epochs), accuracy, label = 'Training accuracy')
plt.plot(range(epochs), valAccuracy, label = 'Validation accuracy')
plt.legend(loc='lower right')
plt.title('Training and validation accuracy')

plt.subplot(1, 2, 2)
plt.plot(range(epochs), loss, label = 'Training Loss')
plt.plot(range(epochs), valLoss, label = 'Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and validation loss')
plt.show()

# save model
model.save('finalModel.h5')

# model summary
model.summary()

Step9. 최종 적용

import numpy as np
from google.colab import files
from keras.preprocessing import image

upLoaded=files.upload()

for dataset in upLoaded.keys():
  path='/content/' + dataset
  imageFile=image.load_img(path, target_size=(150, 150))

  index=image.img_to_array(imageFile)
  index=np.expand_dims(index, axis=0)
  images = np.vstack([index])
  result = model.predict(images, batch_size=10)

  #print('최종 결과값: ', result[0])

  if result[0]>0:
    print( dataset + " 는 강아지입니다. ")
  else:
    print( dataset + " 는 고양이입니다. ")


